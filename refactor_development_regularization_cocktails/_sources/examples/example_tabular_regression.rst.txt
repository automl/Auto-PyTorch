
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/example_tabular_regression.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_example_tabular_regression.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_example_tabular_regression.py:


======================
Tabular Regression
======================

The following example shows how to fit a sample classification model
with AutoPyTorch

.. GENERATED FROM PYTHON SOURCE LINES 9-117




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <smac.runhistory.runhistory.RunHistory object at 0x7f5733f7ddf0> [TrajEntry(train_perf=2147483648, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 32
      encoder:__choice__, Value: 'NoEncoder'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:use_weight_decay, Value: True
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:Lookahead:la_alpha, Value: 0.6
      trainer:StandardTrainer:Lookahead:la_steps, Value: 6
      trainer:StandardTrainer:se_lastk, Constant: 3
      trainer:StandardTrainer:use_lookahead_optimizer, Value: True
      trainer:StandardTrainer:use_snapshot_ensemble, Value: True
      trainer:StandardTrainer:use_stochastic_weight_averaging, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=0, ta_time_used=0.0, wallclock_time=0.002031564712524414, budget=0), TrajEntry(train_perf=0.0005457103106970562, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 32
      encoder:__choice__, Value: 'NoEncoder'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:use_weight_decay, Value: True
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:Lookahead:la_alpha, Value: 0.6
      trainer:StandardTrainer:Lookahead:la_steps, Value: 6
      trainer:StandardTrainer:se_lastk, Constant: 3
      trainer:StandardTrainer:use_lookahead_optimizer, Value: True
      trainer:StandardTrainer:use_snapshot_ensemble, Value: True
      trainer:StandardTrainer:use_stochastic_weight_averaging, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=1, ta_time_used=10.666279315948486, wallclock_time=14.508682012557983, budget=5.555555555555555)]
    {'r2': 0.9996852145039441}






|

.. code-block:: default

    import os
    import tempfile as tmp
    import typing
    import warnings

    from sklearn.datasets import make_regression

    from autoPyTorch.data.tabular_feature_validator import TabularFeatureValidator

    os.environ['JOBLIB_TEMP_FOLDER'] = tmp.gettempdir()
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'

    warnings.simplefilter(action='ignore', category=UserWarning)
    warnings.simplefilter(action='ignore', category=FutureWarning)

    from sklearn import model_selection, preprocessing

    from autoPyTorch.api.tabular_regression import TabularRegressionTask
    from autoPyTorch.datasets.tabular_dataset import TabularDataset
    from autoPyTorch.utils.hyperparameter_search_space_update import HyperparameterSearchSpaceUpdates


    def get_search_space_updates():
        """
        Search space updates to the task can be added using HyperparameterSearchSpaceUpdates
        Returns:
            HyperparameterSearchSpaceUpdates
        """
        updates = HyperparameterSearchSpaceUpdates()
        updates.append(node_name="data_loader",
                       hyperparameter="batch_size",
                       value_range=[16, 512],
                       default_value=32)
        updates.append(node_name="lr_scheduler",
                       hyperparameter="CosineAnnealingLR:T_max",
                       value_range=[50, 60],
                       default_value=55)
        updates.append(node_name='network_backbone',
                       hyperparameter='ResNetBackbone:dropout',
                       value_range=[0, 0.5],
                       default_value=0.2)
        return updates


    if __name__ == '__main__':
        ############################################################################
        # Data Loading
        # ============

        # Get the training data for tabular regression
        # X, y = datasets.fetch_openml(name="cholesterol", return_X_y=True)

        # Use dummy data for now since there are problems with categorical columns
        X, y = make_regression(
            n_samples=5000,
            n_features=4,
            n_informative=3,
            n_targets=1,
            shuffle=True,
            random_state=0
        )

        X_train, X_test, y_train, y_test = model_selection.train_test_split(
            X,
            y,
            random_state=1,
        )

        # Scale the regression targets to have zero mean and unit variance.
        # This is important for Neural Networks since predicting large target values would require very large weights.
        # One can later rescale the network predictions like this: y_pred = y_pred_scaled * y_train_std + y_train_mean
        y_train_mean = y_train.mean()
        y_train_std = y_train.std()

        y_train_scaled = (y_train - y_train_mean) / y_train_std
        y_test_scaled = (y_test - y_train_mean) / y_train_std

        ############################################################################
        # Build and fit a regressor
        # ==========================
        api = TabularRegressionTask(
            delete_tmp_folder_after_terminate=False,
            search_space_updates=get_search_space_updates()
        )
        api.search(
            X_train=X_train,
            y_train=y_train_scaled,
            X_test=X_test.copy(),
            y_test=y_test_scaled.copy(),
            optimize_metric='r2',
            total_walltime_limit=500,
            func_eval_time_limit=50,
            traditional_per_total_budget=0
        )

        ############################################################################
        # Print the final ensemble performance
        # ====================================
        print(api.run_history, api.trajectory)
        y_pred_scaled = api.predict(X_test)

        # Rescale the Neural Network predictions into the original target range
        y_pred = y_pred_scaled * y_train_std + y_train_mean
        score = api.score(y_pred, y_test)

        print(score)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 8 minutes  46.158 seconds)


.. _sphx_glr_download_examples_example_tabular_regression.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/Auto-PyTorch/refactor_development?urlpath=lab/tree/notebooks/examples/example_tabular_regression.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_tabular_regression.py <example_tabular_regression.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_tabular_regression.ipynb <example_tabular_regression.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
