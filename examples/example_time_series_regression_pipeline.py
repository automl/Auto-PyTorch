"""
======================
Ensemble from random search
---------------------------

This is a temporal example to make sure that ensemble works.
It also sets how SMAC should create the output information,
so that the ensemble builder works.

We will remove this file, once SMAC + ensemble builder work
======================
"""

import numpy as np
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sktime.datasets import load_italy_power_demand

from autoPyTorch.data.time_series_validator import TimeSeriesInputValidator
from autoPyTorch.datasets.resampling_strategy import CrossValTypes
from autoPyTorch.datasets.time_series_dataset import TimeSeriesDataset
from autoPyTorch.pipeline.time_series_classification import TimeSeriesClassificationPipeline
from autoPyTorch.utils.backend import Backend, create
from autoPyTorch.utils.hyperparameter_search_space_update import HyperparameterSearchSpaceUpdates
from autoPyTorch.utils.pipeline import get_dataset_requirements


def get_data_to_train(backend: Backend):
    """
    This function returns a fit dictionary that within itself, contains all
    the information to fit a pipeline
    """

    X_train_pd, y_train = load_italy_power_demand(split='train', return_X_y=True)
    X_test_pd, y_test = load_italy_power_demand(split='test', return_X_y=True)

    # Create some regression values.
    # Make the value y equal to the sum of the X values at time-steps 1 and 10.
    X_train = np.zeros((len(X_train_pd), 24, 1), dtype=float)
    y_train = np.zeros(len(y_train), dtype=float)
    for i in range(len(X_train_pd)):
        y_train[i] = X_train_pd.iloc[i].iloc[0].iloc[1]
        y_train[i] = y_train[i] + X_train_pd.iloc[i].iloc[0].iloc[10]
        X_train[i] = X_train_pd.iloc[i].iloc[0][:, np.newaxis]

    X_test = np.zeros((len(X_test_pd), 24, 1), dtype=float)
    y_test = np.zeros(len(y_test))
    for i in range(len(X_test_pd)):
        y_test[i] = X_test_pd.iloc[i].iloc[0].iloc[1]
        y_test[i] = y_test[i] + X_test_pd.iloc[i].iloc[0].iloc[10]
        X_test[i] = X_test_pd.iloc[i].iloc[0][:, np.newaxis]

    validator = TimeSeriesInputValidator(is_classification=False)
    validator.fit(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)

    # Create a datamanager for this toy problem
    datamanager = TimeSeriesDataset(
        X=X_train, Y=y_train,
        X_test=X_test, Y_test=y_test,
        validator=validator
    )
    backend.save_datamanager(datamanager)

    info = {'task_type': datamanager.task_type,
            'numerical_features': datamanager.numerical_features,
            'categorical_features': datamanager.categorical_features,
            'output_type': datamanager.output_type,
            'issparse': datamanager.issparse}

    dataset_properties = datamanager.get_dataset_properties(get_dataset_requirements(info))

    # Fit the pipeline
    fit_dictionary = {
        'X_train': X_train,
        'y_train': y_train,
        'train_indices': np.arange(X_train.shape[0]),
        'dataset_properties': dataset_properties,
        # Training configuration
        'num_run': 5,
        'working_dir': './tmp/example_ensemble_1',  # Hopefully generated by backend
        'device': 'cpu',
        'runtime': 100,
        'torch_num_threads': 1,
        'early_stopping': 20,
        'use_tensorboard_logger': True,
        'use_pynisher': False,
        'memory_limit': 4096,
        'metrics_during_training': True,
        'seed': 0,
        'budget_type': 'epochs',
        'epochs': 100.0,
        'split_id': 0,
        'backend': backend,
        'job_id': 1
    }

    return fit_dictionary, X_train, y_train, X_test, y_test


if __name__ == "__main__":
    # Build a repository with random fitted models
    backend = create(temporary_directory=None, output_directory=None,
                     delete_tmp_folder_after_terminate=False)

    # Create the directory structure
    backend._make_internals_directory()

    updates = HyperparameterSearchSpaceUpdates()
    updates.append(node_name="optimizer",
                   hyperparameter="AdamOptimizer:lr",
                   value_range=[0.0001, 0.001],
                   default_value=0.0005)

    # Get data to train
    fit_dictionary, X_train, y_train, X_test, y_test = get_data_to_train(backend)
    pipeline = TimeSeriesClassificationPipeline(
        dataset_properties=fit_dictionary['dataset_properties'],
        search_space_updates=updates,
        include={
            'network_backbone': ['InceptionTimeBackbone']
        }
    )

    # Goal: Able to indicate a network type and train it successfully on dummy data
    # Step1: Be able to select and MLP with desired hyperparameters
    pipeline_cs = pipeline.get_hyperparameter_search_space()
    print(pipeline_cs)
    config = pipeline_cs.get_default_configuration()
    pipeline.set_hyperparameters(config)
    print(config)

    ## Step2: train it on dummy data

    ## Fit the pipeline
    print("Fitting the pipeline...")
    something = pipeline.fit(fit_dictionary)

    ## Showcase some components of the pipeline
    # print(pipeline)

    from sktime.regression import compose

    tsf = compose.TimeSeriesForestRegressor()
    tsf.fit(np.moveaxis(X_train, 1, 2), y_train)
    tsf_predictions = tsf.predict(np.moveaxis(X_test, 1, 2))

    predictions = pipeline.predict(X_test)
    print(f"r2={r2_score(y_test, predictions)}")
    print(f"tsf r2={r2_score(y_test, tsf_predictions)}")
