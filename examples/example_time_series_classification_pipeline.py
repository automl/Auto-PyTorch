"""
======================
Example for the time series classification pipeline
---------------------------

This is a temporal example to make sure that ensemble works.
It also sets how SMAC should create the output information,
so that the ensemble builder works.

We will remove this file, once SMAC + ensemble builder work
======================
"""
import typing

import numpy as np
import sklearn
from sklearn.metrics import accuracy_score

from autoPyTorch.data.time_series_validator import TimeSeriesInputValidator
from autoPyTorch.datasets.resampling_strategy import CrossValTypes
from autoPyTorch.datasets.time_series_dataset import TimeSeriesDataset
from autoPyTorch.pipeline.time_series_classification import TimeSeriesClassificationPipeline
from autoPyTorch.utils.backend import Backend, create
from autoPyTorch.utils.hyperparameter_search_space_update import HyperparameterSearchSpaceUpdates
from autoPyTorch.utils.pipeline import get_dataset_requirements


def get_data_to_train(backend: Backend):
    """
    This function returns a fit dictionary that within itself, contains all
    the information to fit a pipeline
    """

    from sktime.datasets import load_gunpoint

    data, labels = load_gunpoint(return_X_y=True)

    data = [data.iloc[i][0].values for i in range(len(data))]
    labels = [int(labels.iloc[i]) for i in range(len(labels))]

    data = np.vstack(data)
    X = data[..., np.newaxis]
    y = np.array(labels) - 1  # minus one because labels are initially in {1, 2}

    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(
        X,
        y,
        random_state=1,
        stratify=y
    )

    validator = TimeSeriesInputValidator(is_classification=True)
    validator.fit(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)

    # Create a datamanager for this toy problem
    datamanager = TimeSeriesDataset(
        X=X_train, Y=y_train,
        X_test=X_test, Y_test=y_test,
        validator=validator,
        resampling_strategy=CrossValTypes.stratified_k_fold_cross_validation
    )
    backend.save_datamanager(datamanager)

    info = {'task_type': datamanager.task_type,
            'numerical_features': datamanager.numerical_features,
            'categorical_features': datamanager.categorical_features,
            'output_type': datamanager.output_type,
            'issparse': datamanager.issparse}

    dataset_properties = datamanager.get_dataset_properties(get_dataset_requirements(info))

    # Fit the pipeline
    fit_dictionary = {
        'X_train': X_train,
        'y_train': y_train,
        'train_indices': np.arange(X_train.shape[0]),
        'dataset_properties': dataset_properties,
        # Training configuration
        'num_run': 5,
        'working_dir': './tmp/example_ensemble_1',  # Hopefully generated by backend
        'device': 'cuda',
        'runtime': 50,
        'torch_num_threads': 1,
        'early_stopping': 20,
        'use_tensorboard_logger': True,
        'use_pynisher': False,
        'memory_limit': 4096,
        'metrics_during_training': True,
        'seed': 0,
        'budget_type': 'epochs',
        'epochs': 100.0,
        'split_id': 0,
        'backend': backend,
        'job_id': 1
    }

    return fit_dictionary, X_train, y_train, X_test, y_test


if __name__ == "__main__":
    # Build a repository with random fitted models
    backend = create(temporary_directory=None, output_directory=None,
                     delete_tmp_folder_after_terminate=False)

    # Create the directory structure
    backend._make_internals_directory()

    updates = HyperparameterSearchSpaceUpdates()
    updates.append(node_name="optimizer",
                   hyperparameter="AdamOptimizer:lr",
                   value_range=[0.0001, 0.001],
                   default_value=0.0005)

    # Get data to train
    fit_dictionary, X_train, y_train, X_test, y_test = get_data_to_train(backend)
    pipeline = TimeSeriesClassificationPipeline(
        dataset_properties=fit_dictionary['dataset_properties'],
        search_space_updates=updates,
        include={
            'network_backbone': ['InceptionTimeBackbone']
        }
    )

    # Goal: Able to indicate a network type and train it successfully on dummy data
    # Step1: Be able to select and MLP with desired hyperparameters
    pipeline_cs = pipeline.get_hyperparameter_search_space()
    print(pipeline_cs)
    config = pipeline_cs.get_default_configuration()
    pipeline.set_hyperparameters(config)
    print(config)

    ## Step2: train it on dummy data

    ## Fit the pipeline
    print("Fitting the pipeline...")
    something = pipeline.fit(fit_dictionary)

    ## Showcase some components of the pipeline
    # print(pipeline)

    from sktime.classification import compose

    tsf = compose.TimeSeriesForestClassifier()
    tsf.fit(np.moveaxis(X_train, 1, 2), y_train)
    tsf_predictions = tsf.predict(np.moveaxis(X_test, 1, 2))

    ## Showcase performance of pipeline
    # print(pipeline.named_steps['trainer'].run_summary.performance_tracker)

    predictions = pipeline.predict_proba(X_test)
    predictions = np.array(predictions).argmax(axis=1)
    print(f"accuracy={accuracy_score(y_test, predictions)}")
    print(f"tsf accuracy={accuracy_score(y_test, tsf_predictions)}")
