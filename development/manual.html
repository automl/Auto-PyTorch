<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Manual &#8212; AutoPyTorch 0.1.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>

  </head><body>
  
  <a href="https://github.com/automl/Auto-PyTorch"
     class="visible-desktop hidden-xs"><img
    id="gh-banner"
    style="position: absolute; top: 50px; right: 0; border: 0;"
    src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"
    alt="Fork me on GitHub"></a>
  <script>
    // Adjust banner height.
    $(function () {
      var navHeight = $(".navbar .container").css("height");
      $("#gh-banner").css("top", navHeight);
    });
  </script>


  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Auto-PyTorch</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="index.html">Start</a></li>
                <li><a href="releases.html">Releases</a></li>
                <li><a href="installation.html">Installation</a></li>
                <li><a href="#">Manual</a></li>
                <li><a href="examples/index.html">Examples</a></li>
                <li><a href="api.html">API</a></li>
                <li><a href="dev.html">Dev</a></li>
                <li><a href="extending.html">Extending</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Manual</a><ul>
<li><a class="reference internal" href="#examples">Examples</a></li>
<li><a class="reference internal" href="#data-validation">Data validation</a></li>
<li><a class="reference internal" href="#data-preprocessing">Data Preprocessing</a></li>
<li><a class="reference internal" href="#resource-allocation">Resource Allocation</a></li>
<li><a class="reference internal" href="#ensemble-building-process">Ensemble Building Process</a></li>
<li><a class="reference internal" href="#inspecting-the-results">Inspecting the results</a></li>
<li><a class="reference internal" href="#parallel-computation">Parallel computation</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  <section id="manual">
<span id="id1"></span><h1>Manual<a class="headerlink" href="#manual" title="Permalink to this heading">¶</a></h1>
<p>This manual shows how to get started with Auto-PyTorch. We recommend going over the examples first.
There are additional recommendations on how to interact with the API, further below in this manual.
However, you are welcome to contribute to this documentation by making a Pull-Request.</p>
<p>The searching starts by calling <cite>search()</cite> function of each supported task.
Currently, we are supporting Tabular classification and Tabular Regression.
We expand the support to image processing tasks in the future.</p>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="examples/20_basics/example_tabular_classification.html">Classification</a></p></li>
<li><p><a class="reference external" href="examples/20_basics/example_tabular_regression.html">Regression</a></p></li>
<li><p><a class="reference external" href="examples/40_advanced/example_custom_configuration_space.html">Customizing the search space</a></p></li>
<li><p><a class="reference external" href="examples/40_advanced/example_resampling_strategy.html">Changing the resampling strategy</a></p></li>
<li><p><a class="reference external" href="examples/40_advanced/example_visualization.html">Visualizing the results</a></p></li>
</ul>
</section>
<section id="data-validation">
<h2>Data validation<a class="headerlink" href="#data-validation" title="Permalink to this heading">¶</a></h2>
<p>For tabular tasks, <em>Auto-PyTorch</em> uses a feature and target validator on the input feature set and target set respectively.</p>
<p>The feature validator checks whether the data is supported by <em>Auto-PyTorch</em> or not. Additionally, a sklearn column transformer
is also used which imputes and ordinally encodes the categorical columns of the dataset. This ensures
that no unseen category is found while fitting the data.</p>
<p>The target validator applies a label encoder on the target column.</p>
</section>
<section id="data-preprocessing">
<h2>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this heading">¶</a></h2>
<p>The tabular preprocessing pipeline in <em>Auto-PyTorch</em> consists of</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://github.com/automl/Auto-PyTorch/tree/development/autoPyTorch/pipeline/components/preprocessing/tabular_preprocessing/imputation">Imputation</a></p></li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/automl/Auto-PyTorch/tree/development/autoPyTorch/pipeline/components/preprocessing/tabular_preprocessing/encoding">Encoding</a></dt><dd><p>Choice of <cite>OneHotEncoder</cite> or no encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/automl/Auto-PyTorch/tree/development/autoPyTorch/pipeline/components/preprocessing/tabular_preprocessing/scaling">Scaling</a></dt><dd><p>Choice of <cite>MinMaxScaler</cite>, <cite>Normalizer</cite>, <cite>StandardScaler</cite> and no scaling.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://github.com/automl/Auto-PyTorch/tree/development/autoPyTorch/pipeline/components/preprocessing/tabular_preprocessing/feature_preprocessing">Feature preprocessing</a></dt><dd><p>Choice of <cite>FastICA</cite>, <cite>KernelPCA</cite>, <cite>RandomKitchenSinks</cite>, <cite>Nystroem</cite>, <cite>PolynomialFeatures</cite>, <cite>PowerTransformer</cite>, <cite>TruncatedSVD</cite>,</p>
</dd>
</dl>
</li>
</ol>
<p>Along with the choices, their corresponding hyperparameters are also tuned. A sklearn ColumnTransformer is
created which includes a categorical pipeline and a numerical pipeline. These pipelines are made up of the
relevant preprocessors chosen in the previous steps. The column transformer is compatible with <a class="reference external" href="https://pytorch.org/vision/stable/transforms.html">torchvision transforms</a>
and is therefore passed to the DataLoader.</p>
</section>
<section id="resource-allocation">
<h2>Resource Allocation<a class="headerlink" href="#resource-allocation" title="Permalink to this heading">¶</a></h2>
<p><em>Auto-PyTorch</em> allows to control the maximum allowed resident set size memory (RSS) that an estimator can use.
By providing the <cite>memory_limit</cite> argument to the <cite>search()</cite> method, one can make sure that neither the individual
machine learning models fitted by SMAC nor the final ensemble consume more than <cite>memory_limit</cite> megabytes.</p>
<p>Additionally, one can control the allocated time to search for a model via the argument <cite>total_walltime_limit</cite>
to the <cite>search()</cite> method. This argument controls the total time SMAC can use to search for new configurations.
The more time is allocated, the better the final estimator will be.</p>
</section>
<section id="ensemble-building-process">
<h2>Ensemble Building Process<a class="headerlink" href="#ensemble-building-process" title="Permalink to this heading">¶</a></h2>
<p><em>Auto-PyTorch</em> uses ensemble selection by <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/1015330.1015432">Caruana et al. (2004)</a>
to build an ensemble based on the models’ prediction for the validation set. The following hyperparameters control how the ensemble is constructed:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">ensemble_size</span></code></dt><dd><p>determines the maximal size of the ensemble. If it is set to zero, no ensemble will be constructed.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">ensemble_nbest</span></code></dt><dd><p>allows the user to directly specify the number of models considered for the ensemble. When an integer
is provided for this hyperparameter, the final ensemble chooses each predictor from only the best n models.
If a float between 0.0 and 1.0 is provided, <code class="docutils literal notranslate"><span class="pre">ensemble_nbest</span></code> would be interpreted as a fraction suggesting
the percentage of models to use in the ensemble building process (namely, if ensemble_nbest is a float,
library pruning is implemented as described in <a class="reference external" href="https://dl.acm.org/doi/10.1109/ICDM.2006.76">Caruana et al. (2006)</a>).
For example, if 10 candidates are available for the ensemble building process and the hyper-parameter is <cite>ensemble_nbest==0.7`</cite>,
we build an ensemble by taking the best 7 models among the original 10 candidate models.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">max_models_on_disc</span></code></dt><dd><p>defines the maximum number of models that are kept on the disc, as a mechanism to control the amount of disc space
consumed by Auto-PyTorch. Throughout the automl process, different individual models are optimized, and their
predictions (and other metadata) are stored on disc. The user can set the upper bound on how many models are
acceptable to keep on disc, yet this variable takes priority in the definition of the number of models used by
the ensemble builder (that is, the minimum of <code class="docutils literal notranslate"><span class="pre">ensemble_size</span></code>, <code class="docutils literal notranslate"><span class="pre">ensemble_nbest</span></code> and <code class="docutils literal notranslate"><span class="pre">max_models_on_disc</span></code>
determines the maximal amount of models used in the ensemble). If set to None, this feature is disabled.</p>
</dd>
</dl>
</li>
</ul>
</section>
<section id="inspecting-the-results">
<h2>Inspecting the results<a class="headerlink" href="#inspecting-the-results" title="Permalink to this heading">¶</a></h2>
<p>Auto-PyTorch allows users to inspect the training results and statistics. The following example shows how different statistics can be printed for the inspection.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">autoPyTorch.api.tabular_classification</span> <span class="kn">import</span> <span class="n">TabularClassificationTask</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">automl</span> <span class="o">=</span> <span class="n">TabularClassificationTask</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">automl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">automl</span><span class="o">.</span><span class="n">show_models</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="parallel-computation">
<h2>Parallel computation<a class="headerlink" href="#parallel-computation" title="Permalink to this heading">¶</a></h2>
<p>In it’s default mode, <em>Auto-PyTorch</em> already uses two cores. The first one is used for model building, the second for building an ensemble every time a new machine learning model has finished training.</p>
<p>Nevertheless, <em>Auto-PyTorch</em> also supports parallel Bayesian optimization via the use of <a class="reference external" href="https://distributed.dask.org/">Dask.distributed</a>. By providing the arguments <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> to the estimator construction, one can control the number of cores available to <em>Auto-PyTorch</em> (As shown in the Example <a class="reference internal" href="examples/40_advanced/example_parallel_n_jobs.html#sphx-glr-examples-40-advanced-example-parallel-n-jobs-py"><span class="std std-ref">Tabular Classification with n parallel jobs</span></a>). When multiple cores are available, <em>Auto-PyTorch</em> will create a worker per core, and use the  available workers to both search for better machine learning models as well as building  an ensemble with them until the time resource is exhausted.</p>
<p><strong>Note:</strong> <em>Auto-PyTorch</em> requires all workers to have access to a shared file system for storing training data and models.</p>
<p><em>Auto-PyTorch</em> employs <a class="reference external" href="https://github.com/joblib/threadpoolctl/">threadpoolctl</a> to control the number of threads employed by scientific libraries like numpy or scikit-learn. This is done exclusively during the building procedure of models, not during inference. In particular, <em>Auto-PyTorch</em> allows each pipeline to use at most 1 thread during training. At predicting and scoring time this limitation is not enforced by <em>Auto-PyTorch</em>. You can control the number of resources
employed by the pipelines by setting the following variables in your environment, prior to running <em>Auto-PyTorch</em>:</p>
<div class="highlight-shell-session notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span> <span class="nv">OPENBLAS_NUM_THREADS</span><span class="o">=</span><span class="m">1</span>
<span class="gp">$ </span><span class="nb">export</span> <span class="nv">MKL_NUM_THREADS</span><span class="o">=</span><span class="m">1</span>
<span class="gp">$ </span><span class="nb">export</span> <span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
<p>For further information about how scikit-learn handles multiprocessing, please check the <a class="reference external" href="https://scikit-learn.org/stable/computing/parallelism.html">Parallelism, resource management, and configuration</a> documentation from the library.</p>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/manual.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2014-2022, Machine Learning Professorship Freiburg.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.0.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>