
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_resampling_strategy.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_resampling_strategy.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_resampling_strategy.py:


======================
Tabular Classification with different resampling strategy
======================

The following example shows how to fit a sample classification model
with different resampling strategies in AutoPyTorch
By default, AutoPyTorch uses Holdout Validation with
a 67% train size split.

.. GENERATED FROM PYTHON SOURCE LINES 11-30

.. code-block:: default

    import os
    import tempfile as tmp
    import warnings

    os.environ['JOBLIB_TEMP_FOLDER'] = tmp.gettempdir()
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'

    warnings.simplefilter(action='ignore', category=UserWarning)
    warnings.simplefilter(action='ignore', category=FutureWarning)

    import sklearn.datasets
    import sklearn.model_selection

    from autoPyTorch.api.tabular_classification import TabularClassificationTask
    from autoPyTorch.datasets.resampling_strategy import CrossValTypes, HoldoutValTypes









.. GENERATED FROM PYTHON SOURCE LINES 31-33

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 33-40

.. code-block:: default

    X, y = sklearn.datasets.fetch_openml(data_id=40981, return_X_y=True, as_frame=True)
    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(
        X,
        y,
        random_state=1,
    )








.. GENERATED FROM PYTHON SOURCE LINES 41-43

Build and fit a classifier with default resampling strategy
===========================================================

.. GENERATED FROM PYTHON SOURCE LINES 43-52

.. code-block:: default

    api = TabularClassificationTask(
        # 'HoldoutValTypes.holdout_validation' with 'val_share': 0.33
        # is the default argument setting for TabularClassificationTask.
        # It is explicitly specified in this example for demonstrational
        # purpose.
        resampling_strategy=HoldoutValTypes.holdout_validation,
        resampling_strategy_args={'val_share': 0.33}
    )








.. GENERATED FROM PYTHON SOURCE LINES 53-55

Search for an ensemble of machine learning algorithms
=====================================================

.. GENERATED FROM PYTHON SOURCE LINES 55-65

.. code-block:: default

    api.search(
        X_train=X_train,
        y_train=y_train,
        X_test=X_test.copy(),
        y_test=y_test.copy(),
        optimize_metric='accuracy',
        total_walltime_limit=150,
        func_eval_time_limit_secs=30
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <autoPyTorch.api.tabular_classification.TabularClassificationTask object at 0x7f911521da00>



.. GENERATED FROM PYTHON SOURCE LINES 66-68

Print the final ensemble performance
====================================

.. GENERATED FROM PYTHON SOURCE LINES 68-75

.. code-block:: default

    print(api.run_history, api.trajectory)
    y_pred = api.predict(X_test)
    score = api.score(y_pred, y_test)
    print(score)
    # Print the final ensemble built by AutoPyTorch
    print(api.show_models())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <smac.runhistory.runhistory.RunHistory object at 0x7f91153b6fd0> [TrajEntry(train_perf=2147483648, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=0, ta_time_used=0.0, wallclock_time=0.001377105712890625, budget=0), TrajEntry(train_perf=0.17543859649122806, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=1, ta_time_used=4.95233154296875, wallclock_time=5.990574359893799, budget=5.555555555555555)]
    {'accuracy': 0.8728323699421965}
    |    | Preprocessing                                                     | Estimator                                                          |   Weight |
    |---:|:------------------------------------------------------------------|:-------------------------------------------------------------------|---------:|
    |  0 | SimpleImputer,OneHotEncoder,MinMaxScaler,Nystroem                 | no embedding,ShapedResNetBackbone,FullyConnectedHead,nn.Sequential |     0.28 |
    |  1 | SimpleImputer,OneHotEncoder,StandardScaler,PolynomialFeatures     | embedding,ShapedResNetBackbone,FullyConnectedHead,nn.Sequential    |     0.24 |
    |  2 | None                                                              | CBLearner                                                          |     0.18 |
    |  3 | None                                                              | RFLearner                                                          |     0.12 |
    |  4 | None                                                              | ETLearner                                                          |     0.06 |
    |  5 | None                                                              | KNNLearner                                                         |     0.06 |
    |  6 | SimpleImputer,OneHotEncoder,Normalizer,KitchenSink                | embedding,MLPBackbone,FullyConnectedHead,nn.Sequential             |     0.04 |
    |  7 | SimpleImputer,OneHotEncoder,StandardScaler,NoFeaturePreprocessing | no embedding,ShapedMLPBackbone,FullyConnectedHead,nn.Sequential    |     0.02 |




.. GENERATED FROM PYTHON SOURCE LINES 78-80

Build and fit a classifier with Cross validation resampling strategy
====================================================================

.. GENERATED FROM PYTHON SOURCE LINES 80-85

.. code-block:: default

    api = TabularClassificationTask(
        resampling_strategy=CrossValTypes.k_fold_cross_validation,
        resampling_strategy_args={'num_splits': 3}
    )








.. GENERATED FROM PYTHON SOURCE LINES 86-88

Search for an ensemble of machine learning algorithms
=====================================================

.. GENERATED FROM PYTHON SOURCE LINES 88-98

.. code-block:: default

    api.search(
        X_train=X_train,
        y_train=y_train,
        X_test=X_test.copy(),
        y_test=y_test.copy(),
        optimize_metric='accuracy',
        total_walltime_limit=150,
        func_eval_time_limit_secs=30
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <autoPyTorch.api.tabular_classification.TabularClassificationTask object at 0x7f9114e71fa0>



.. GENERATED FROM PYTHON SOURCE LINES 99-101

Print the final ensemble performance
====================================

.. GENERATED FROM PYTHON SOURCE LINES 101-108

.. code-block:: default

    print(api.run_history, api.trajectory)
    y_pred = api.predict(X_test)
    score = api.score(y_pred, y_test)
    print(score)
    # Print the final ensemble built by AutoPyTorch
    print(api.show_models())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <smac.runhistory.runhistory.RunHistory object at 0x7f9114e71c70> [TrajEntry(train_perf=2147483648, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=0, ta_time_used=0.0, wallclock_time=0.0014412403106689453, budget=0), TrajEntry(train_perf=0.16252805214194727, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=1, ta_time_used=14.339972496032715, wallclock_time=15.385104656219482, budget=5.555555555555555)]
    {'accuracy': 0.884393063583815}
    |    | Preprocessing   | Estimator               |   Weight |
    |---:|:----------------|:------------------------|---------:|
    |  0 | None            | TabularTraditionalModel |     0.98 |
    |  1 | None            | TabularTraditionalModel |     0.02 |




.. GENERATED FROM PYTHON SOURCE LINES 111-113

Build and fit a classifier with Stratified resampling strategy
==============================================================

.. GENERATED FROM PYTHON SOURCE LINES 113-121

.. code-block:: default

    api = TabularClassificationTask(
        # For demonstration purposes, we use
        # Stratified hold out validation. However,
        # one can also use CrossValTypes.stratified_k_fold_cross_validation.
        resampling_strategy=HoldoutValTypes.stratified_holdout_validation,
        resampling_strategy_args={'val_share': 0.33}
    )








.. GENERATED FROM PYTHON SOURCE LINES 122-124

Search for an ensemble of machine learning algorithms
=====================================================

.. GENERATED FROM PYTHON SOURCE LINES 124-134

.. code-block:: default

    api.search(
        X_train=X_train,
        y_train=y_train,
        X_test=X_test.copy(),
        y_test=y_test.copy(),
        optimize_metric='accuracy',
        total_walltime_limit=150,
        func_eval_time_limit_secs=30
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <autoPyTorch.api.tabular_classification.TabularClassificationTask object at 0x7f9114e9aaf0>



.. GENERATED FROM PYTHON SOURCE LINES 135-137

Print the final ensemble performance
====================================

.. GENERATED FROM PYTHON SOURCE LINES 137-143

.. code-block:: default

    print(api.run_history, api.trajectory)
    y_pred = api.predict(X_test)
    score = api.score(y_pred, y_test)
    print(score)
    # Print the final ensemble built by AutoPyTorch
    print(api.show_models())




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <smac.runhistory.runhistory.RunHistory object at 0x7f9114e9ab80> [TrajEntry(train_perf=2147483648, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=0, ta_time_used=0.0, wallclock_time=0.0014071464538574219, budget=0), TrajEntry(train_perf=0.19883040935672514, incumbent_id=1, incumbent=Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      imputer:numerical_strategy, Value: 'mean'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'StandardScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , ta_runs=1, ta_time_used=4.993889808654785, wallclock_time=6.040158748626709, budget=5.555555555555555)]
    {'accuracy': 0.861271676300578}
    |    | Preprocessing                                             | Estimator                                                          |   Weight |
    |---:|:----------------------------------------------------------|:-------------------------------------------------------------------|---------:|
    |  0 | SimpleImputer,OneHotEncoder,Normalizer,KitchenSink        | embedding,MLPBackbone,FullyConnectedHead,nn.Sequential             |     0.22 |
    |  1 | None                                                      | KNNLearner                                                         |     0.2  |
    |  2 | None                                                      | CBLearner                                                          |     0.14 |
    |  3 | None                                                      | SVMLearner                                                         |     0.12 |
    |  4 | SimpleImputer,OneHotEncoder,MinMaxScaler,Nystroem         | no embedding,ShapedResNetBackbone,FullyConnectedHead,nn.Sequential |     0.12 |
    |  5 | SimpleImputer,OneHotEncoder,Normalizer,PolynomialFeatures | no embedding,ResNetBackbone,FullyConnectedHead,nn.Sequential       |     0.06 |
    |  6 | None                                                      | RFLearner                                                          |     0.06 |
    |  7 | SimpleImputer,OneHotEncoder,StandardScaler,Nystroem       | no embedding,ResNetBackbone,FullyConnectedHead,nn.Sequential       |     0.04 |
    |  8 | None                                                      | LGBMLearner                                                        |     0.02 |
    |  9 | None                                                      | ETLearner                                                          |     0.02 |





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 9 minutes  4.414 seconds)


.. _sphx_glr_download_examples_40_advanced_example_resampling_strategy.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/Auto-PyTorch/development?urlpath=lab/tree/notebooks/examples/40_advanced/example_resampling_strategy.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_resampling_strategy.py <example_resampling_strategy.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_resampling_strategy.ipynb <example_resampling_strategy.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
