
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_single_configuration.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_single_configuration.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_single_configuration.py:


==========================
Fit a single configuration
==========================
*Auto-PyTorch* searches for the best combination of machine learning algorithms
and their hyper-parameter configuration for a given task.
This example shows how one can fit one of these pipelines, both, with a user defined
configuration, and a randomly sampled one form the configuration space.
The pipelines that Auto-PyTorch fits are compatible with Scikit-Learn API. You can
get further documentation about Scikit-Learn models here: <https://scikit-learn.org/stable/getting_started.html`>_

.. GENERATED FROM PYTHON SOURCE LINES 13-32

.. code-block:: default

    import os
    import tempfile as tmp
    import warnings

    os.environ['JOBLIB_TEMP_FOLDER'] = tmp.gettempdir()
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'

    warnings.simplefilter(action='ignore', category=UserWarning)
    warnings.simplefilter(action='ignore', category=FutureWarning)

    import sklearn.datasets
    import sklearn.metrics

    from autoPyTorch.api.tabular_classification import TabularClassificationTask
    from autoPyTorch.datasets.resampling_strategy import HoldoutValTypes









.. GENERATED FROM PYTHON SOURCE LINES 33-35

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 35-41

.. code-block:: default


    X, y = sklearn.datasets.fetch_openml(data_id=3, return_X_y=True, as_frame=True)
    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(
        X, y, test_size=0.5, random_state=3
    )








.. GENERATED FROM PYTHON SOURCE LINES 42-44

Define an estimator
===================

.. GENERATED FROM PYTHON SOURCE LINES 44-50

.. code-block:: default


    estimator = TabularClassificationTask(
        resampling_strategy=HoldoutValTypes.holdout_validation,
        resampling_strategy_args={'val_share': 0.5},
    )








.. GENERATED FROM PYTHON SOURCE LINES 51-53

Get a configuration of the pipeline for current dataset
===============================================================

.. GENERATED FROM PYTHON SOURCE LINES 53-62

.. code-block:: default


    dataset = estimator.get_dataset(X_train=X_train,
                                    y_train=y_train,
                                    X_test=X_test,
                                    y_test=y_test,
                                    dataset_name='kr-vs-kp')
    configuration = estimator.get_search_space(dataset).get_default_configuration()

    print("Passed Configuration:", configuration)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Passed Configuration: Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'NoScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'





.. GENERATED FROM PYTHON SOURCE LINES 63-65

Fit the configuration
=====================

.. GENERATED FROM PYTHON SOURCE LINES 65-82

.. code-block:: default


    pipeline, run_info, run_value, dataset = estimator.fit_pipeline(dataset=dataset,
                                                                    configuration=configuration,
                                                                    budget_type='epochs',
                                                                    budget=10,
                                                                    run_time_limit_secs=100
                                                                    )

    # The fit_pipeline command also returns a named tuple with the pipeline constraints
    print(run_info)

    # The fit_pipeline command also returns a named tuple with train/test performance
    print(run_value)

    # This object complies with Scikit-Learn Pipeline API.
    # https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html
    print(pipeline.named_steps)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    RunInfo(config=Configuration:
      data_loader:batch_size, Value: 64
      encoder:__choice__, Value: 'OneHotEncoder'
      feature_preprocessor:__choice__, Value: 'NoFeaturePreprocessor'
      imputer:categorical_strategy, Value: 'most_frequent'
      lr_scheduler:ReduceLROnPlateau:factor, Value: 0.1
      lr_scheduler:ReduceLROnPlateau:mode, Value: 'min'
      lr_scheduler:ReduceLROnPlateau:patience, Value: 10
      lr_scheduler:__choice__, Value: 'ReduceLROnPlateau'
      network_backbone:ShapedMLPBackbone:activation, Value: 'relu'
      network_backbone:ShapedMLPBackbone:max_units, Value: 200
      network_backbone:ShapedMLPBackbone:mlp_shape, Value: 'funnel'
      network_backbone:ShapedMLPBackbone:num_groups, Value: 5
      network_backbone:ShapedMLPBackbone:output_dim, Value: 200
      network_backbone:ShapedMLPBackbone:use_dropout, Value: False
      network_backbone:__choice__, Value: 'ShapedMLPBackbone'
      network_embedding:__choice__, Value: 'NoEmbedding'
      network_head:__choice__, Value: 'fully_connected'
      network_head:fully_connected:activation, Value: 'relu'
      network_head:fully_connected:num_layers, Value: 2
      network_head:fully_connected:units_layer_1, Value: 128
      network_init:XavierInit:bias_strategy, Value: 'Normal'
      network_init:__choice__, Value: 'XavierInit'
      optimizer:AdamOptimizer:beta1, Value: 0.9
      optimizer:AdamOptimizer:beta2, Value: 0.9
      optimizer:AdamOptimizer:lr, Value: 0.01
      optimizer:AdamOptimizer:weight_decay, Value: 0.0
      optimizer:__choice__, Value: 'AdamOptimizer'
      scaler:__choice__, Value: 'NoScaler'
      trainer:StandardTrainer:weighted_loss, Value: True
      trainer:__choice__, Value: 'StandardTrainer'
    , instance=None, instance_specific=None, seed=1, cutoff=94, capped=False, budget=10, source_id=0)
    RunValue(cost=0.021276595744680882, time=53.957823038101196, status=<StatusType.SUCCESS: 1>, starttime=1643122578.643471, endtime=1643122633.652623, additional_info={'opt_loss': {'accuracy': 0.021276595744680882}, 'duration': 53.882060050964355, 'num_run': 2, 'train_loss': {'accuracy': 0.006257822277847325}, 'test_loss': {'accuracy': 0.03191489361702127}, 'configuration_origin': None})
    {'imputer': SimpleImputer(random_state=RandomState(MT19937) at 0x7F01B0AD7D40), 'encoder': <autoPyTorch.pipeline.components.preprocessing.tabular_preprocessing.encoding.EncoderChoice object at 0x7f01ac5e2ee0>, 'scaler': <autoPyTorch.pipeline.components.preprocessing.tabular_preprocessing.scaling.ScalerChoice object at 0x7f01ac5e2220>, 'feature_preprocessor': <autoPyTorch.pipeline.components.preprocessing.tabular_preprocessing.feature_preprocessing.FeatureProprocessorChoice object at 0x7f01ac5e2df0>, 'tabular_transformer': TabularColumnTransformer(random_state=RandomState(MT19937) at 0x7F01B0AD7D40), 'preprocessing': EarlyPreprocessing(random_state=RandomState(MT19937) at 0x7F01B0AD7D40), 'network_embedding': <autoPyTorch.pipeline.components.setup.network_embedding.NetworkEmbeddingChoice object at 0x7f01afc6b1f0>, 'network_backbone': <autoPyTorch.pipeline.components.setup.network_backbone.NetworkBackboneChoice object at 0x7f01b008cac0>, 'network_head': <autoPyTorch.pipeline.components.setup.network_head.NetworkHeadChoice object at 0x7f024237a9d0>, 'network': NetworkComponent(network=Sequential(
      (0): _NoEmbedding()
      (1): Sequential(
        (0): Linear(in_features=73, out_features=200, bias=True)
        (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=200, bias=True)
        (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5):...
        (10): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (11): ReLU()
        (12): Linear(in_features=200, out_features=200, bias=True)
      )
      (2): Sequential(
        (0): Flatten(start_dim=1, end_dim=-1)
        (1): Linear(in_features=200, out_features=128, bias=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=2, bias=True)
      )
    ),
                     random_state=RandomState(MT19937) at 0x7F01B0AD7D40), 'network_init': <autoPyTorch.pipeline.components.setup.network_initializer.NetworkInitializerChoice object at 0x7f01af137e80>, 'optimizer': <autoPyTorch.pipeline.components.setup.optimizer.OptimizerChoice object at 0x7f01af137400>, 'lr_scheduler': <autoPyTorch.pipeline.components.setup.lr_scheduler.SchedulerChoice object at 0x7f01af554700>, 'data_loader': FeatureDataLoader(random_state=RandomState(MT19937) at 0x7F01B0AD7D40), 'trainer': <autoPyTorch.pipeline.components.training.trainer.TrainerChoice object at 0x7f01b02adb80>}





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  3.750 seconds)


.. _sphx_glr_download_examples_40_advanced_example_single_configuration.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/Auto-PyTorch/development?urlpath=lab/tree/notebooks/examples/40_advanced/example_single_configuration.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_single_configuration.py <example_single_configuration.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_single_configuration.ipynb <example_single_configuration.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
