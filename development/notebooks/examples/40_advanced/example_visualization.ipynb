{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualizing the Results\n\nAuto-Pytorch uses SMAC to fit individual machine learning algorithms\nand then ensembles them together using `Ensemble Selection\n<https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml04.icdm06long.pdf>`_.\n\nThe following examples shows how to visualize both the performance\nof the individual models and their respective ensemble.\n\nAdditionally, as we are compatible with scikit-learn,\nwe show how to further interact with `Scikit-Learn Inspection\n<https://scikit-learn.org/stable/inspection.html>`_ support.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport pickle\nimport tempfile as tmp\nimport time\nimport warnings\n\n# The following variables are not needed for every unix distribution, but are\n# highlighted in here to prevent problems with multiprocessing with scikit-learn.\nos.environ['JOBLIB_TEMP_FOLDER'] = tmp.gettempdir()\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['OPENBLAS_NUM_THREADS'] = '1'\nos.environ['MKL_NUM_THREADS'] = '1'\n\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport pandas as pd\n\n\nimport sklearn.datasets\nimport sklearn.model_selection\nfrom sklearn.inspection import permutation_importance\n\nfrom smac.tae import StatusType\n\n\nfrom autoPyTorch.api.tabular_classification import TabularClassificationTask\nfrom autoPyTorch.metrics import accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We will use the iris dataset for this Toy example\nseed = 42\nX, y = sklearn.datasets.fetch_openml(data_id=61, return_X_y=True, as_frame=True)\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    X,\n    y,\n    random_state=42,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and fit a classifier\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "api = TabularClassificationTask(seed=seed)\napi.search(\n    X_train=X_train,\n    y_train=y_train,\n    X_test=X_test.copy(),\n    y_test=y_test.copy(),\n    optimize_metric=accuracy.name,\n    total_walltime_limit=200,\n    func_eval_time_limit_secs=50\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One can also save the model for future inference\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For more details on how to deploy a model, please check\n# `Scikit-Learn persistence\n# <https://scikit-learn.org/stable/modules/model_persistence.html>`_ support.\nwith open('estimator.pickle', 'wb') as handle:\n    pickle.dump(api, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n# Then let us read it back and use it for our analysis\nwith open('estimator.pickle', 'rb') as handle:\n    estimator = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the model performance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We will plot the search incumbent through time.\n\n# Collect the performance of individual machine learning algorithms\n# found by SMAC\nindividual_performances = []\nfor run_key, run_value in estimator.run_history.data.items():\n    if run_value.status != StatusType.SUCCESS:\n        # Ignore crashed runs\n        continue\n    individual_performances.append({\n        'Timestamp': pd.Timestamp(\n            time.strftime(\n                '%Y-%m-%d %H:%M:%S',\n                time.localtime(run_value.endtime)\n            )\n        ),\n        'single_best_optimization_accuracy': accuracy._optimum - run_value.cost,\n        'single_best_test_accuracy': np.nan if run_value.additional_info is None else\n        accuracy._optimum - run_value.additional_info['test_loss'],\n    })\nindividual_performance_frame = pd.DataFrame(individual_performances)\n\n# Collect the performance of the ensemble through time\n# This ensemble is built from the machine learning algorithms\n# found by SMAC\nensemble_performance_frame = pd.DataFrame(estimator.ensemble_performance_history)\n\n# As we are tracking the incumbent, we are interested in the cummax() performance\nensemble_performance_frame['ensemble_optimization_accuracy'] = ensemble_performance_frame[\n    'train_accuracy'\n].cummax()\nensemble_performance_frame['ensemble_test_accuracy'] = ensemble_performance_frame[\n    'test_accuracy'\n].cummax()\nensemble_performance_frame.drop(columns=['test_accuracy', 'train_accuracy'], inplace=True)\nindividual_performance_frame['single_best_optimization_accuracy'] = individual_performance_frame[\n    'single_best_optimization_accuracy'\n].cummax()\nindividual_performance_frame['single_best_test_accuracy'] = individual_performance_frame[\n    'single_best_test_accuracy'\n].cummax()\n\npd.merge(\n    ensemble_performance_frame,\n    individual_performance_frame,\n    on=\"Timestamp\", how='outer'\n).sort_values('Timestamp').fillna(method='ffill').plot(\n    x='Timestamp',\n    kind='line',\n    legend=True,\n    title='Auto-PyTorch accuracy over time',\n    grid=True,\n)\nplt.show()\n\n# We then can understand the importance of each input feature using\n# a permutation importance analysis. This is done as a proof of concept, to\n# showcase that we can leverage of scikit-learn API.\nresult = permutation_importance(estimator, X_train, y_train, n_repeats=5,\n                                scoring='accuracy',\n                                random_state=seed)\nsorted_idx = result.importances_mean.argsort()\n\nfig, ax = plt.subplots()\nax.boxplot(result.importances[sorted_idx].T,\n           vert=False, labels=X_test.columns[sorted_idx])\nax.set_title(\"Permutation Importances (Train set)\")\nfig.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}