{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Time Series Forecasting\n\nThe following example shows how to fit a sample forecasting model\nwith AutoPyTorch. This is only a dummmy example because of the limited size of the dataset.\nThus, it could be possible that the AutoPyTorch model does not perform as well as a dummy predictor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport tempfile as tmp\nimport warnings\nimport copy\n\nos.environ['JOBLIB_TEMP_FOLDER'] = tmp.gettempdir()\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['OPENBLAS_NUM_THREADS'] = '1'\nos.environ['MKL_NUM_THREADS'] = '1'\n\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom sktime.datasets import load_longley\ntargets, features = load_longley()\n\nforecasting_horizon = 3\n\n# each series represent an element in the List\n# we take the last forecasting_horizon  as test targets. The itme before that as training targets\n# Normally the value to be forecasted should follow the training sets\ny_train = [targets[: -forecasting_horizon]]\ny_test = [targets[-forecasting_horizon:]]\n\n# same for features. For uni-variant models, X_train, X_test can be omitted\nX_train = [features[: -forecasting_horizon]]\n# Here x_test indicates the 'known future features': they are the features known previously, features that are unknown\n# could be replaced with NAN or zeros (which will not be used by our networks). If no feature is known beforehand,\n# we could also omit X_test\nknown_future_features = list(features.columns)\nX_test = [features[-forecasting_horizon:]]\n\nstart_times = [targets.index.to_timestamp()[0]]\nfreq = '1Y'\n\nfrom autoPyTorch.api.time_series_forecasting import TimeSeriesForecastingTask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and fit a forecaster\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "api = TimeSeriesForecastingTask()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search for an ensemble of machine learning algorithms\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "api.search(\n    X_train=X_train,\n    y_train=copy.deepcopy(y_train),\n    X_test=X_test,\n    optimize_metric='mean_MASE_forecasting',\n    n_prediction_steps=forecasting_horizon,\n    memory_limit=16 * 1024,  # Currently, forecasting models need much more memories than it actually requires\n    freq=freq,\n    start_times=start_times,\n    func_eval_time_limit_secs=50,\n    total_walltime_limit=60,\n    min_num_test_instances=1000,  # proxy validation sets. This only works for the tasks with more than 1000 series\n    known_future_features=known_future_features,\n)\n\n\nfrom autoPyTorch.datasets.time_series_dataset import TimeSeriesSequence\n\ntest_sets = []\n\n# We could construct test sets from scratch\nfor feature, future_feature, target, start_time in zip(X_train, X_test,y_train, start_times):\n    test_sets.append(\n        TimeSeriesSequence(X=feature.values,\n                           Y=target.values,\n                           X_test=future_feature.values,\n                           start_time=start_time,\n                           is_test_set=True,\n                           # additional information required to construct a new time series sequence\n                           **api.dataset.sequences_builder_kwargs\n                           )\n    )\n# Alternatively, if we only want to forecast the value after the X_train, we could directly ask datamanager to\n# generate a test set:\n# test_sets2 = api.dataset.generate_test_seqs()\n\npred = api.predict(test_sets)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}